{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pymssql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = LinearRegression()\n",
    "qt = QuantileTransformer(output_distribution=\"normal\")\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "pipe = make_pipeline(poly, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = \"mssql-82792-0.cloudclusters.net:16272\"\n",
    "username = \"user\"\n",
    "password = \"RiceOwls1912\" \n",
    "dfbase = \"ghz\"\n",
    "string = \"mssql+pymssql://\" + username + \":\" + password + \"@\" + server + \"/\" + dfbase\n",
    "conn = create_engine(string).connect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(\n",
    "    \"\"\"\n",
    "    select ticker, date, ret, roeq, bm, mom12m, mve\n",
    "    from data\n",
    "    where date>='2000-01'\n",
    "    order by date, ticker\n",
    "    \"\"\", \n",
    "    conn\n",
    ")\n",
    "df = df.dropna()\n",
    "conn.close()\n",
    "\n",
    "features = [\"roeq\", \"bm\", \"mom12m\"]\n",
    "df = df.set_index([\"date\", \"ticker\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop largest 500 stocks each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"size_rnk\"] = df.groupby(\"date\").mve.rank(ascending=False)\n",
    "df = df[df.size_rnk>500]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform features each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qt_df(d):\n",
    "    x = qt.fit_transform(d)\n",
    "    return pd.DataFrame(x, columns=d.columns, index=d.index)\n",
    "\n",
    "df[features] = df.groupby(\"date\", group_keys=False)[features].apply(qt_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform target each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qt_ser(s):\n",
    "    x = s.copy()\n",
    "    x = x.to_numpy().reshape(-1, 1)\n",
    "    x = qt.fit_transform(x).flatten()\n",
    "    return pd.Series(x, index=s.index)\n",
    "\n",
    "df[\"target\"] = df.groupby(\"date\", group_keys=False).ret.apply(qt_ser)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and predict in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = None\n",
    "\n",
    "dates = [\"2005-01\", \"2010-01\", \"2015-01\", \"2020-01\", \"3000-01\"]\n",
    "for train_date, end_date in zip(dates[:-1], dates[1:]):\n",
    "\n",
    "    filter1 = df.index.get_level_values(\"date\") < train_date\n",
    "    filter2 = df.index.get_level_values(\"date\") < end_date\n",
    "\n",
    "    train = df[filter1]\n",
    "    test = df[~filter1 & filter2]\n",
    "\n",
    "    Xtrain = train[features]\n",
    "    ytrain = train[\"target\"]\n",
    "    Xtest = test[features]\n",
    "\n",
    "    pipe.fit(Xtrain, ytrain)\n",
    "    pred = pipe.predict(Xtest)\n",
    "    pred = pd.Series(pred, index=test.index)\n",
    "    predictions = pd.concat((predictions, pred))\n",
    "\n",
    "df[\"predict\"] = predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute returns of portfolios of best and worst stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"predict\"])\n",
    "\n",
    "numstocks = 200\n",
    "\n",
    "df[\"rnk\"] = df.groupby(\"date\").predict.rank(method=\"first\", ascending=False)\n",
    "best = df[df.rnk<=numstocks]\n",
    "\n",
    "df[\"rnk\"] = df.groupby(\"date\").predict.rank(method=\"first\")\n",
    "worst = df[df.rnk<=numstocks]\n",
    "\n",
    "best_rets = best.groupby(\"date\").ret.mean()\n",
    "worst_rets = worst.groupby(\"date\").ret.mean()\n",
    "rets = pd.concat((best_rets, worst_rets), axis=1)\n",
    "rets.columns = [\"best\", \"worst\"]\n",
    "       \n",
    "rets.to_csv(\"files/rets.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a98f34b6005ae2330f135078450db511ef8910ecc790235ef0560aa88aa6ce12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
